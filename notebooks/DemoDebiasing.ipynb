{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab132f7",
   "metadata": {},
   "source": [
    "# Debiasing a Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abcdd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Computing libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# huggging face\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import evaluate\n",
    "\n",
    "# Custom imports\n",
    "import os\n",
    "import sys\n",
    "ruta_raiz = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")) \\\n",
    "    if \"__file__\" in globals() else os.path.abspath(\"..\")\n",
    "sys.path.insert(0, ruta_raiz)\n",
    "\n",
    "from FairLangProc.datasets import BiasDataLoader\n",
    "from FairLangProc.metrics import WEAT\n",
    "\n",
    "from FairLangProc.algorithms.preprocessors import CDA, BLINDModelForClassification, SentDebiasForSequenceClassification\n",
    "from FairLangProc.algorithms.inprocessors import EARModel, DebiasAdapter, selective_unfreezing \n",
    "from FairLangProc.algorithms.intraprocessors import add_EAT_hook, DiffPrunningBERT, DiffPrunedDebiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc5db4",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c82514fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODELS = [\n",
    "    'bert-base-uncased',\n",
    "    'deepseek-ai/deepseek-llm-7b-base',\n",
    "    'huggyllama/llama-7b'\n",
    "]\n",
    "TASKS = [\n",
    "    \"cola\",\n",
    "    \"sst2\",\n",
    "    \"mrpc\",\n",
    "    \"stsb\",\n",
    "    \"qqp\",\n",
    "    \"mnli\",\n",
    "    \"qnli\",\n",
    "    \"rte\",\n",
    "    \"wnli\"\n",
    "]\n",
    "TASK_LABELS = {\n",
    "    \"cola\": 2,\n",
    "    \"sst2\": 2,\n",
    "    \"mrpc\": 2,\n",
    "    \"qqp\": 2,\n",
    "    \"stsb\": 1,\n",
    "    \"mnli\": 3,\n",
    "    \"qnli\": 2,\n",
    "    \"rte\": 2,\n",
    "    \"wnli\": 2,\n",
    "}\n",
    "DEBIAS_METHODS = [\n",
    "    \"none\",\n",
    "    \"cda\",\n",
    "    \"blind\",\n",
    "    \"embedding\",\n",
    "    \"ear\",\n",
    "    \"adele\",\n",
    "    \"selective\",\n",
    "    \"eat\",\n",
    "    \"diff\"\n",
    "]\n",
    "TASK_METRICS = {\n",
    "    \"cola\": \"eval_matthews_correlation\",\n",
    "    \"sst2\": \"eval_accuracy\",\n",
    "    \"mrpc\": \"eval_accuracy\",\n",
    "    \"stsb\": \"eval_pearson\",\n",
    "    \"mnli\": \"eval_accuracy\",\n",
    "    \"qnli\": \"eval_accuracy\",\n",
    "    \"rte\": \"eval_accuracy\",\n",
    "    \"wnli\": \"eval_accuracy\",\n",
    "}\n",
    "CDA_METHOD = {\n",
    "    \"none\": False,\n",
    "    \"cda\": True,\n",
    "    \"blind\": False,\n",
    "    \"embedding\": False,\n",
    "    \"ear\": False,\n",
    "    \"adele\": True,\n",
    "    \"selective\": True,\n",
    "    \"eat\": False,\n",
    "    \"diff\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4306857",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = MODELS[0]\n",
    "TASK = \"cola\"\n",
    "DEBIAS = \"blind\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7ce127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_FOR_BEST = TASK_METRICS.get(TASK, \"eval_accuracy\")\n",
    "BATCH_SIZE = 16\n",
    "WEIGHT_DECAY = 0.1\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09fb250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_pairs = [\n",
    "    (\"gods\", \"goddesses\"), (\"manager\", \"manageress\"), (\"barons\", \"baronesses\"),\n",
    "    (\"nephew\", \"niece\"), (\"prince\", \"princess\"), (\"boars\", \"sows\"),\n",
    "    (\"baron\", \"baroness\"), (\"stepfathers\", \"stepmothers\"), (\"wizard\", \"witch\"),\n",
    "    (\"father\", \"mother\"), (\"stepsons\", \"stepdaughters\"), (\"sons-in-law\", \"daughters-in-law\"),\n",
    "    (\"dukes\", \"duchesses\"), (\"boyfriend\", \"girlfriend\"), (\"fiances\", \"fiancees\"),\n",
    "    (\"dad\", \"mom\"), (\"shepherd\", \"shepherdess\"), (\"uncles\", \"aunts\"),\n",
    "    (\"beau\", \"belle\"), (\"males\", \"females\"), (\"hunter\", \"huntress\"),\n",
    "    (\"beaus\", \"belles\"), (\"grandfathers\", \"grandmothers\"), (\"lads\", \"lasses\"),\n",
    "    (\"daddies\", \"mummies\"), (\"step-son\", \"step-daughter\"), (\"masters\", \"mistresses\"),\n",
    "    (\"policeman\", \"policewoman\"), (\"nephews\", \"nieces\"), (\"brother\", \"sister\"),\n",
    "    (\"grandfather\", \"grandmother\"), (\"priest\", \"priestess\"), (\"hosts\", \"hostesses\"),\n",
    "    (\"landlord\", \"landlady\"), (\"husband\", \"wife\"), (\"poet\", \"poetess\"),\n",
    "    (\"landlords\", \"landladies\"), (\"fathers\", \"mothers\"), (\"masseur\", \"masseuse\"),\n",
    "    (\"monks\", \"nuns\"), (\"usher\", \"usherette\"), (\"hero\", \"heroine\"),\n",
    "    (\"stepson\", \"stepdaughter\"), (\"postman\", \"postwoman\"), (\"god\", \"goddess\"),\n",
    "    (\"milkmen\", \"milkmaids\"), (\"stags\", \"hinds\"), (\"grandpa\", \"grandma\"),\n",
    "    (\"chairmen\", \"chairwomen\"), (\"husbands\", \"wives\"), (\"grandpas\", \"grandmas\"),\n",
    "    (\"stewards\", \"stewardesses\"), (\"murderer\", \"murderess\"), (\"manservant\", \"maidservant\"),\n",
    "    (\"men\", \"women\"), (\"host\", \"hostess\"), (\"heirs\", \"heiresses\"),\n",
    "    (\"masseurs\", \"masseuses\"), (\"boy\", \"girl\"), (\"male\", \"female\"),\n",
    "    (\"son-in-law\", \"daughter-in-law\"), (\"waiter\", \"waitress\"), (\"tutors\", \"governesses\"),\n",
    "    (\"priests\", \"priestesses\"), (\"bachelor\", \"spinster\"), (\"millionaire\", \"millionairess\"),\n",
    "    (\"steward\", \"stewardess\"), (\"businessmen\", \"businesswomen\"), (\"congressman\", \"congresswoman\"),\n",
    "    (\"emperor\", \"empress\"), (\"duke\", \"duchess\"), (\"sire\", \"dam\"),\n",
    "    (\"son\", \"daughter\"), (\"sirs\", \"madams\"), (\"widower\", \"widow\"),\n",
    "    (\"kings\", \"queens\"), (\"papas\", \"mamas\"), (\"grandsons\", \"granddaughters\"),\n",
    "    (\"proprietor\", \"proprietress\"), (\"monk\", \"nun\"), (\"headmasters\", \"headmistresses\"),\n",
    "    (\"grooms\", \"brides\"), (\"heir\", \"heiress\"), (\"boys\", \"girls\"),\n",
    "    (\"gentleman\", \"lady\"), (\"uncle\", \"aunt\"), (\"he\", \"she\"),\n",
    "    (\"king\", \"queen\"), (\"princes\", \"princesses\"), (\"policemen\", \"policewomen\"),\n",
    "    (\"governor\", \"matron\"), (\"fiance\", \"fiancee\"), (\"step-father\", \"step-mother\"),\n",
    "    (\"waiters\", \"waitresses\"), (\"mr\", \"mrs\"), (\"stepfather\", \"stepmother\"),\n",
    "    (\"daddy\", \"mummy\"), (\"lords\", \"ladies\"), (\"widowers\", \"widows\"),\n",
    "    (\"emperors\", \"empresses\"), (\"father-in-law\", \"mother-in-law\"), (\"abbot\", \"abbess\"),\n",
    "    (\"sir\", \"madam\"), (\"actor\", \"actress\"), (\"mr.\", \"mrs.\"),\n",
    "    (\"wizards\", \"witches\"), (\"actors\", \"actresses\"), (\"chairman\", \"chairwoman\"),\n",
    "    (\"sorcerer\", \"sorceress\"), (\"postmaster\", \"postmistress\"), (\"brothers\", \"sisters\"),\n",
    "    (\"lad\", \"lass\"), (\"headmaster\", \"headmistress\"), (\"papa\", \"mama\"),\n",
    "    (\"milkman\", \"milkmaid\"), (\"heroes\", \"heroines\"), (\"man\", \"woman\"),\n",
    "    (\"grandson\", \"granddaughter\"), (\"groom\", \"bride\"), (\"sons\", \"daughters\"),\n",
    "    (\"congressmen\", \"congresswomen\"), (\"businessman\", \"businesswoman\"), (\"boyfriends\", \"girlfriends\"),\n",
    "    (\"dads\", \"moms\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62a3ca",
   "metadata": {},
   "source": [
    "## Load model and debias method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eed8b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = TASK_LABELS[TASK]\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "original_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "hidden_dim = original_model.config.hidden_size\n",
    "\n",
    "if not hasattr(original_model, 'classifier'):\n",
    "    original_model.classifier = original_model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c41df852",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBIAS in (\"none\", \"cda\", \"eat\"):\n",
    "    model = original_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2811098",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBIAS == \"embedding\":\n",
    "\n",
    "    class SentDebiasBert(SentDebiasForSequenceClassification):        \n",
    "        def _get_embedding(self, input_ids, attention_mask = None, token_type_ids = None):\n",
    "            return self.model.bert(\n",
    "                input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids\n",
    "                ).last_hidden_state[:,0,:]\n",
    "\n",
    "    class SentDebiasAverageAutoreg(SentDebiasForSequenceClassification):\n",
    "        def _get_embedding(self, input_ids, attention_mask = None, token_type_ids = None):\n",
    "            return self.model.model(\n",
    "                input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids\n",
    "                ).last_hidden_state.mean(dim = 1)\n",
    "        \n",
    "    if MODEL_NAME == 'bert-base-uncased':\n",
    "        model = SentDebiasBert(\n",
    "            model = original_model,\n",
    "            config = None,\n",
    "            tokenizer = tokenizer,\n",
    "            word_pairs = counterfactual_pairs,\n",
    "            n_components = 1\n",
    "        )\n",
    "    else:\n",
    "        model = SentDebiasAverageAutoreg(\n",
    "            model = original_model,\n",
    "            config = None,\n",
    "            tokenizer = tokenizer,\n",
    "            word_pairs = counterfactual_pairs,\n",
    "            n_components = 1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "308ef36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBIAS == \"blind\":\n",
    "    \n",
    "    class BLINDBERT(BLINDModelForClassification):\n",
    "        def _get_embedding(self, input_ids = None, attention_mask = None, token_type_ids = None):\n",
    "            return self.model.bert(\n",
    "                input_ids = input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids\n",
    "                ).last_hidden_state[:,0,:]\n",
    "        \n",
    "    class BLINDAverageAutoreg(BLINDModelForClassification):\n",
    "        def _get_embedding(self, input_ids = None, attention_mask = None, token_type_ids = None):\n",
    "            return self.model.model(\n",
    "                input_ids = input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids\n",
    "                ).last_hidden_state.mean(dim = 1)\n",
    "        \n",
    "    if MODEL_NAME == 'bert-base-uncased':\n",
    "        model = BLINDBERT(\n",
    "            model = original_model,\n",
    "            config = None,\n",
    "            gamma=2.0,\n",
    "            temperature=1.0,\n",
    "            size_average=True,\n",
    "            hidden_dim = hidden_dim\n",
    "        )\n",
    "    else:\n",
    "        model = BLINDAverageAutoreg(\n",
    "            model = original_model,\n",
    "            config = None,\n",
    "            gamma=2.0,\n",
    "            temperature=1.0,\n",
    "            size_average=True,\n",
    "            hidden_dim = hidden_dim\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67c6127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBIAS == \"adele\":\n",
    "    model = DebiasAdapter(\n",
    "        model = original_model,\n",
    "        config = 'lora'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd36df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBIAS == \"ear\":\n",
    "    model = EARModel(\n",
    "        model = original_model,\n",
    "        ear_reg_strength = 0.01\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7625cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBIAS == \"selective\":\n",
    "    model = original_model\n",
    "    selective_unfreezing(model, [\"attention.self\", \"attention.output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0294e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBIAS == \"diff\":\n",
    "\n",
    "    class DiffPrunningAvgAutoReg(DiffPrunedDebiasing):\n",
    "        def _get_embedding(self, outputs):\n",
    "            return outputs.mean(dim = 1)\n",
    "        def _get_encoder(self):\n",
    "            self.encoder = self.base_model.model\n",
    "\n",
    "    tokens_male = [words[0] for words in counterfactual_pairs]\n",
    "    tokens_female = [words[1] for words in counterfactual_pairs]\n",
    "\n",
    "    inputs_male = tokenizer(tokens_male, padding = True, return_tensors = \"pt\")\n",
    "    inputs_female = tokenizer(tokens_female, padding = True, return_tensors = \"pt\")\n",
    "\n",
    "    if MODEL_NAME == 'bert-base-uncased':\n",
    "        model = DiffPrunningBERT(\n",
    "            base_model = original_model,\n",
    "            input_ids_A = inputs_male,\n",
    "            input_ids_B = inputs_female\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        model = DiffPrunningAvgAutoReg(\n",
    "            base_model = original_model,\n",
    "            input_ids_A = inputs_male,\n",
    "            input_ids_B = inputs_female\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f7502",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73088bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer, task):\n",
    "    if task in [\"sst2\", \"cola\"]:\n",
    "        return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    elif task in [\"mnli\", \"qnli\", \"rte\", \"wnli\"]:\n",
    "        return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    elif task in [\"mrpc\", \"qqp\"]:\n",
    "        return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    elif task == \"stsb\":\n",
    "        return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    \n",
    "def get_metrics(task_name):\n",
    "    metric = evaluate.load(\"glue\", task_name)\n",
    "    if task_name == \"stsb\":\n",
    "        return metric, lambda logits: np.squeeze(logits, axis=-1)\n",
    "    return metric, lambda logits: np.argmax(logits, axis=-1)\n",
    "\n",
    "def compute_metrics_fn(p, task_name):\n",
    "    logits = p.predictions\n",
    "    labels = p.label_ids\n",
    "\n",
    "    if isinstance(logits, tuple) or isinstance(logits, list):\n",
    "        logits = logits[0]\n",
    "\n",
    "    metric, postprocess_fn = get_metrics(task_name)\n",
    "    predictions = postprocess_fn(logits)\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5a06a",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45dca282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = load_dataset(\"glue\", TASK)\n",
    "\n",
    "if CDA_METHOD[DEBIAS]:\n",
    "    train_dataset = Dataset.from_dict(\n",
    "        CDA(dataset['train'][:], pairs = dict(counterfactual_pairs))\n",
    "        )\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        'validation': dataset[\"validation\"],\n",
    "        \"test\": dataset[\"test\"]\n",
    "        \n",
    "    })\n",
    "    \n",
    "tokenized_datasets = dataset.map(lambda x: preprocess_function(x, tokenizer, TASK), batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7318cc",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a328879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960718/751379173.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1605' max='1605' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1605/1605 10:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.073833</td>\n",
       "      <td>0.550612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.082927</td>\n",
       "      <td>0.567661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.095779</td>\n",
       "      <td>0.577797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in  cola : {'eval_loss': 0.0957789346575737, 'eval_matthews_correlation': 0.577796630208603, 'eval_runtime': 8.1426, 'eval_samples_per_second': 128.093, 'eval_steps_per_second': 8.106, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"output/{TASK}-{DEBIAS}-{MODEL_NAME.replace('/', '-')}\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=METRIC_FOR_BEST\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=lambda p: compute_metrics_fn(p, TASK),\n",
    "    optimizers=(AdamW(model.parameters(), lr=1e-5, weight_decay=WEIGHT_DECAY), None)\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "if DEBIAS == 'eat':\n",
    "    model = add_EAT_hook(\n",
    "        model = model,\n",
    "        beta = 0.7\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=lambda p: compute_metrics_fn(p, TASK),\n",
    "    )\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Results in \", TASK, \":\", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622d772",
   "metadata": {},
   "source": [
    "## WEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c1af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X-A_mean_sim': 0.5240193605422974, 'X-B_mean_sim': 0.6104025840759277, 'Y-A_mean_sim': 0.5816237926483154, 'Y-B_mean_sim': 0.6603400707244873, 'W1_size': 8, 'W2_size': 8, 'A1_size': 8, 'A2_size': 8, 'effect_size': -0.07666268199682236}\n"
     ]
    }
   ],
   "source": [
    "class BertWEAT(WEAT):\n",
    "    def _get_embedding(self, outputs):\n",
    "        return outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "class AverageAutoregWEAT(WEAT):\n",
    "    def _get_embedding(self, outputs):\n",
    "        return outputs.last_hidden_state.mean(dim = 1)\n",
    "    \n",
    "if MODEL_NAME == 'bert-base-uncased':\n",
    "    try:\n",
    "        weat = BertWEAT(model = model.model.bert, tokenizer = tokenizer)\n",
    "    except:\n",
    "        weat = BertWEAT(model = model.bert, tokenizer = tokenizer)\n",
    "else:\n",
    "    try:\n",
    "        weat = AverageAutoregWEAT(model = model.model.base_model, tokenizer = tokenizer)\n",
    "    except:\n",
    "        weat = AverageAutoregWEAT(model = model.base_model, tokenizer = tokenizer)\n",
    "\n",
    "math = ['math', 'algebra', 'geometry', 'calculus', 'equations', 'computation', 'numbers', 'addition']\n",
    "arts = ['poetry', 'art', 'dance', 'literature', 'novel', 'symphony', 'drama', 'sculpture']\n",
    "male = ['male', 'man', 'boy', 'brother', 'he', 'him', 'his', 'son']\n",
    "female = ['female', 'woman', 'girl', 'sister', 'she', 'her', 'hers', 'daughter']\n",
    "\n",
    "bias_results = weat.run_test(\n",
    "    W1_words = math, W2_words = arts,\n",
    "    A1_words = male, A2_words = female,\n",
    "    pval = False\n",
    "    )\n",
    "print(bias_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e45ab",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"output/{TASK}-{DEBIAS}-{MODEL_NAME.replace('/', '-')}/results.json\", \"w\") as f:\n",
    "    json.dump({\"eval\": eval_results, \"bias\": bias_results}, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FairLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
