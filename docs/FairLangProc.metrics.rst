FairLangProc.metrics package
============================

FairLangProc supports different fairness metrics to measure discrimination in NLP. Broadly, they can be classified into three categories:
* Embedding metrics: if they measure bias by examining the model's hidden representations of input text.
* Probability metrics: if they measure bias by computing the probabilities of certain tokens or sentences.
* Generated text metrics: if they measure bias by examining text generated by the model, looking for harmful or stereotypical words.

The supported metrics are:
* Generalized association tests (WEAT) ([Caliskan et al., 2016](https://arxiv.org/abs/1608.07187))
* Log Probability Bias Score (LPBS) ([Kurita et al., 2019](https://arxiv.org/abs/1906.07337))
* Categorical Bias Score (CBS) ([Ahn et al., 2021](https://aclanthology.org/2021.emnlp-main.42/))
* CrowS-Pairs Score (CPS) ([Nangia et al., 2020](https://aclanthology.org/2020.emnlp-main.154/))
* All Unmasked Score (AUL) ([Kaneko et al., 2021](https://arxiv.org/abs/2104.07496))
* Demographic Representation (DR) ([Liang et al., 2022](https://arxiv.org/abs/2211.09110))
* Stereotypical Association (SA) ([Liang et al., 2022](https://arxiv.org/abs/2211.09110))
* HONEST ([Nozza et al., 2021](https://aclanthology.org/2021.naacl-main.191/))

FairLangProc.metrics.embedding module
-------------------------------------

.. automodule:: FairLangProc.metrics.embedding
   :members: WEAT, BertWEAT
   :undoc-members: 
   :show-inheritance:

FairLangProc.metrics.generated\_text module
-------------------------------------------

.. automodule:: FairLangProc.metrics.generated_text
   :members: DemRep, StereoAsoc, HONEST
   :undoc-members:
   :show-inheritance:

FairLangProc.metrics.probability module
---------------------------------------

.. automodule:: FairLangProc.metrics.probability
   :members: LPBS, CBS, CPS, AUL
   :undoc-members:
   :show-inheritance:
