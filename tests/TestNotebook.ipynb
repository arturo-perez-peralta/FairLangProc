{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f077304",
   "metadata": {},
   "source": [
    "# Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36538d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pytest\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset as PtDataset\n",
    "from datasets import Dataset as HfDataset\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")) if \"__file__\" in globals() else os.path.abspath(\"..\")\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "\n",
    "from FairLangProc.datasets.fairness_datasets import BiasDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fda3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPLEMENTED = [\n",
    "    \"BBQ\",\n",
    "    \"BEC-Pro\",\n",
    "    \"BOLD\",\n",
    "    \"BUG\",\n",
    "    \"CrowS-Pairs\",\n",
    "    \"GAP\",\n",
    "    \"StereoSet\",\n",
    "    \"UnQover\",\n",
    "    \"WinoBias+\",\n",
    "    \"WinoBias\",\n",
    "    \"Winogender\"\n",
    "]\n",
    "\n",
    "DATASETS = [\n",
    "    \"BBQ\",\n",
    "    \"BEC-Pro\",\n",
    "    \"BOLD\",\n",
    "    \"BUG\",\n",
    "    \"Bias-NLI\",\n",
    "    \"CrowS-Pairs\",\n",
    "    \"GAP\",\n",
    "    \"Grep-BiasIR\",\n",
    "    \"HONEST\",\n",
    "    \"HolisticBias\",\n",
    "    \"PANDA\",\n",
    "    \"RedditBias\",\n",
    "    \"StereoSet\",\n",
    "    \"TrustGPT\",\n",
    "    \"UnQover\",\n",
    "    \"WinoBias\",\n",
    "    \"WinoBias+\",\n",
    "    \"WinoQueer\",\n",
    "    \"Winogender\",\n",
    "]\n",
    "\n",
    "REMAINING = [dataset for dataset in DATASETS if dataset not in IMPLEMENTED]\n",
    "\n",
    "CONFIGURATIONS = {\n",
    "    \"BBQ\": [\"Age\", \"Disability_Status\", \"Gender_identity\", \"Nationality\", \"Physical_appearance\", \"Race_ethnicity\", \"Race_x_gender\", \"Race_x_SES\", \"Religion\", \"SES\", \"Sexual_orientation\", \"all\"],\n",
    "    \"BEC-Pro\": [\"english\", \"german\", \"all\"],\n",
    "    \"BOLD\": [\"prompts\", \"wikipedia\", \"all\"],\n",
    "    \"BUG\": [\"balanced\", \"full\", \"gold\", \"all\"],\n",
    "    \"Bias-NLI\": [\"process\", \"load\", \"all\"],\n",
    "    \"CrowS-Pairs\": [\"\"],\n",
    "    \"GAP\": [\"\"],\n",
    "    \"Grep-BiasIR\": [\"queries\", \"documents\", \"relevance\", \"all\"],\n",
    "    \"HolisticBias\": [\"noun_phrases\", \"sentences\", \"all\"],\n",
    "    \"PANDA\": [\"train\", \"test\", \"dev\", \"all\"],\n",
    "    \"RedditBias\": [\"posts\", \"comments\", \"annotations\", \"all\"],\n",
    "    \"StereoSet\": [\"word\", \"sentence\", \"all\"],\n",
    "    \"TrustGPT\": [\"process\", \"load\", \"all\", \"benchmarks\"],\n",
    "    \"UnQover\": [\"questions\", \"answers\", \"annotations\"],\n",
    "    \"WinoBias\": [\"pairs\", \"WinoBias\"],\n",
    "    \"WinoBias+\": [\"\"],\n",
    "    \"WinoQueer\": [\"sentences\", \"templates\", \"annotations\", \"all\"],\n",
    "    \"Winogender\": [\"\"],\n",
    "}\n",
    "\n",
    "FORMATS = [\"hf\", \"pt\", \"raw\"]\n",
    "\n",
    "CLASS_DICT = {\n",
    "    \"hf\": HfDataset,\n",
    "    \"pt\": PtDataset,\n",
    "    \"raw\": pd.DataFrame\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb867e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CASES_FORMAT = [\n",
    "    (dataset, config, format)\n",
    "    for dataset in CONFIGURATIONS.keys()\n",
    "    for config in CONFIGURATIONS[dataset] \n",
    "    for format in FORMATS if dataset in IMPLEMENTED\n",
    "]\n",
    "\n",
    "@pytest.mark.parametrize(\"dataset, config, format\", TEST_CASES_FORMAT)\n",
    "def test_format(dataset, config, format):\n",
    "    result = BiasDataLoader(dataset = dataset, config = config, format = format)\n",
    "    assert isinstance(result, dict)\n",
    "    for key in result:\n",
    "        assert isinstance(result[key], CLASS_DICT[format])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37c645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_columns():\n",
    "    for dataset in CONFIGURATIONS.keys():\n",
    "        if dataset in IMPLEMENTED:\n",
    "            result = BiasDataLoader(dataset = dataset, config = 'all', format = 'raw')\n",
    "            if result is None:\n",
    "                result = BiasDataLoader(dataset = dataset, config = '', format = 'raw')\n",
    "            try:\n",
    "                print(dataset)\n",
    "                print(list(result[list(result.keys())[0]].keys()))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def _get_rows():\n",
    "    for dataset in CONFIGURATIONS.keys():\n",
    "        if dataset in IMPLEMENTED:\n",
    "            result = BiasDataLoader(dataset = dataset, config = 'all', format = 'raw')\n",
    "            if result is None:\n",
    "                result = BiasDataLoader(dataset = dataset, config = '', format = 'raw')\n",
    "            try:\n",
    "                string = f\"\\\"{dataset}\\\": {{\"\n",
    "                for data in result.keys():\n",
    "                    if data == 'templates' and dataset == 'BBQ':\n",
    "                        continue\n",
    "                    string += f\"\\\"{data}\\\": {len(result[data].index)}, \"\n",
    "                string += \"}, \"\n",
    "                print(string)\n",
    "            except:\n",
    "                print(dataset + \": nothing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a467f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = {\n",
    "    \"BBQ\": ['example_id', 'question_index', 'question_polarity', 'context_condition', 'category', 'answer_info', 'additional_metadata', 'context', 'question', 'ans0', 'ans1', 'ans2', 'label'],\n",
    "    \"BEC-Pro\": ['Unnamed: 0', 'Sentence', 'Sent_TM', 'Sent_AM', 'Sent_TAM', 'Template', 'Person', 'Gender', 'Profession', 'Prof_Gender'],\n",
    "    \"BOLD\": ['gender_prompt.json', 'political_ideology_prompt.json', 'profession_prompt.json', 'race_prompt.json', 'religious_ideology_prompt.json'],\n",
    "    \"BUG\": ['Unnamed: 0', 'sentence_text', 'tokens', 'profession', 'g', 'profession_first_index', 'g_first_index', 'predicted gender', 'stereotype', 'distance', 'num_of_pronouns', 'corpus', 'data_index'],\n",
    "    \"CrowS-Pairs\": ['Unnamed: 0', 'sent_more', 'sent_less', 'stereo_antistereo', 'bias_type', 'annotations', 'anon_writer', 'anon_annotators'],\n",
    "    \"GAP\": ['ID', 'Text', 'Pronoun', 'Pronoun-offset', 'A', 'A-offset', 'A-coref', 'B', 'B-offset', 'B-coref', 'URL'],\n",
    "    \"HolisticBias\": None,\n",
    "    \"StereoSet\": ['options', 'context', 'target', 'bias_type', 'labels'],\n",
    "    \"WinoBias+\": ['gendered', 'neutral'],\n",
    "    \"WinoBias\": ['sentence', 'entity', 'pronoun'],\n",
    "    \"Winogender\": ['sentid', 'sentence']\n",
    "}\n",
    "\n",
    "TEST_CASES_COLUMNS = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59239f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = {\n",
    "    \"BBQ\": {\"Age.jsonl\": 3680, \"Disability_status.jsonl\": 1556, \"Gender_identity.jsonl\": 5672, \"Nationality.jsonl\": 3080, \"Physical_appearance.jsonl\": 1576, \"Race_ethnicity.jsonl\": 6880, \"Race_x_SES.jsonl\": 11160, \"Race_x_gender.jsonl\": 15960, \"Religion.jsonl\": 1200, \"SES.jsonl\": 6864, \"Sexual_orientation.jsonl\": 864, \"additional_metadata.csv\": 58556, },\n",
    "    \"BEC-Pro\": {\"english\": 5400, \"german\": 5400, }, \n",
    "    \"BUG\": {\"balanced_BUG.csv\": 25504, \"full_BUG.csv\": 105687, \"gold_BUG.csv\": 1717, }, \n",
    "    \"CrowS-Pairs\": {\"data\": 1508, }, \n",
    "    \"GAP\": {\"gap-development.tsv\": 2000, \"gap-test.tsv\": 2000, \"gap-validation.tsv\": 454, }, \n",
    "    \"StereoSet\": {\"test_sentence\": 6374, \"test_word\": 6392, \"dev_sentence\": 2123, \"dev_word\": 2106, }, \n",
    "    \"WinoBias\": {\"anti_stereotyped_type1.txt.dev\": 396, \"anti_stereotyped_type1.txt.test\": 396, \"anti_stereotyped_type2.txt.dev\": 396, \"anti_stereotyped_type2.txt.test\": 396, \"pro_stereotyped_type1.txt.dev\": 396, \"pro_stereotyped_type1.txt.test\": 396, \"pro_stereotyped_type2.txt.dev\": 396, \"pro_stereotyped_type2.txt.test\": 396, }, \n",
    "    \"WinoBias+\": {\"data\": 3167, }, \n",
    "    \"Winogender\": {\"data\": 720, }, \n",
    "}\n",
    "\n",
    "TEST_CASES_ROWS = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc3b414",
   "metadata": {},
   "source": [
    "# Test metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8a112",
   "metadata": {},
   "source": [
    "## Test probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45f0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import pytest\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")) if \"__file__\" in globals() else os.path.abspath(\"..\")\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "\n",
    "from FairLangProc.metrics import LPBS, CBS, CPS, AUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e5469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({dict.__repr__(self)})\"\n",
    "    \n",
    "\n",
    "class DummyModel:\n",
    "    def __call__(self, **kwargs):\n",
    "        input_ids = kwargs[\"input_ids\"]\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "\n",
    "        logits = torch.zeros(batch_size, seq_len, 30522)\n",
    "\n",
    "        mask_token_id = 103\n",
    "        mask_positions = (input_ids == mask_token_id)\n",
    "        \n",
    "        # introduce dependency on input_ids\n",
    "        for b in range(batch_size):\n",
    "            for t in range(seq_len):\n",
    "                if mask_positions[b, t]:\n",
    "                    input_sum = input_ids[b].sum().item()\n",
    "\n",
    "                    # Logic depending on sentence and word\n",
    "                    logits[b, t, 200] = 5.0 + input_sum % 3     # doctor\n",
    "                    logits[b, t, 201] = -5.0 + input_sum % 4    # nurse\n",
    "                    logits[b, t, 202] = 15.0 - input_sum % 5    # engineer\n",
    "\n",
    "                    logits[b, t, 300] = 5.0 + input_sum % 2     # science\n",
    "                    logits[b, t, 301] = -5.0 + input_sum % 6    # art\n",
    "                    logits[b, t, 302] = 15.0 - input_sum % 7    # math\n",
    "\n",
    "                    logits[b, t, 400] = 10.0 + input_sum % 3    # he\n",
    "                    logits[b, t, 401] = -10.0 + input_sum % 4   # she\n",
    "                    logits[b, t, 402] = -15.0 + input_sum % 10  # it\n",
    "        return AttrDict(logits=logits)\n",
    "    \n",
    "\n",
    "class DummyTokenizer:\n",
    "    pad_token_type_id = 101\n",
    "    cls_token_id = 102\n",
    "    mask_token_id = 103\n",
    "    hash_map_tokens = {\n",
    "        '[PAD]': pad_token_type_id,\n",
    "        '[CLS]': cls_token_id,\n",
    "        '[MASK]': mask_token_id,\n",
    "        'doctor': 200,\n",
    "        'nurse': 201,\n",
    "        'engineer': 202,\n",
    "        'science': 300,\n",
    "        'art': 301,\n",
    "        'math': 302,\n",
    "        'he': 400,\n",
    "        'she': 401,\n",
    "        'it': 402,\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def __call__(self, sentences, padding=True, return_tensors=\"pt\"):\n",
    "        split = [sentence.split() for sentence in sentences]\n",
    "        maxLen = max([len(sentence) for sentence in split])\n",
    "        ids = [[self.convert_tokens_to_ids(word) for word in sentence] for sentence in split]\n",
    "        if padding:\n",
    "            for i in range(len(ids)):\n",
    "                lenId = len(ids[i])\n",
    "                if lenId < maxLen:\n",
    "                    ids[i] = ids[i] + [self.pad_token_id for _ in range(maxLen - lenId)] \n",
    "        return AttrDict(**{\"input_ids\": torch.tensor(ids)})\n",
    "\n",
    "    def tokenize(self, word):\n",
    "        return [word]\n",
    "\n",
    "    def convert_tokens_to_ids(self, token):\n",
    "        return self.hash_map_tokens.get(token, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d3933ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = DummyModel()\n",
    "TOKENIZER = DummyTokenizer()\n",
    "\n",
    "SENTENCES = [\n",
    "    \"[MASK] is a [MASK]\",\n",
    "    \"Is [MASK] a [MASK] ?\",\n",
    "    \"[MASK] teaches [MASK]\"\n",
    "]\n",
    "\n",
    "TARGET_WORDS_LPBS = [\n",
    "    (\"he\", \"she\"),\n",
    "    (\"he\", \"she\"),\n",
    "    (\"he\", \"she\")\n",
    "]\n",
    "\n",
    "TARGET_WORDS_CBS = [\n",
    "    (\"he\", \"she\", \"it\"),\n",
    "    (\"he\", \"she\", \"it\"),\n",
    "    (\"he\", \"she\", \"it\")\n",
    "]\n",
    "\n",
    "FILL_WORDS = [\n",
    "    'engineer',\n",
    "    'doctor',\n",
    "    'math',\n",
    "]\n",
    "\n",
    "MASK_INDICES = [0, 0, 0]\n",
    "\n",
    "def test_lpbs_type():\n",
    "    LPBSscore = LPBS(\n",
    "        model = MODEL,\n",
    "        tokenizer = TOKENIZER,\n",
    "        sentences = SENTENCES,\n",
    "        target_words = TARGET_WORDS_LPBS,\n",
    "        fill_words = FILL_WORDS,\n",
    "        mask_indices = MASK_INDICES\n",
    "    )\n",
    "    assert isinstance(LPBSscore, torch.Size)\n",
    "    assert LPBSscore.shape == torch.Size([3])\n",
    "\n",
    "def test_lpbs_value():\n",
    "    LPBSscore = LPBS(\n",
    "        model = MODEL,\n",
    "        tokenizer = TOKENIZER,\n",
    "        sentences = SENTENCES,\n",
    "        target_words = TARGET_WORDS_LPBS,\n",
    "        fill_words = FILL_WORDS,\n",
    "        mask_indices = MASK_INDICES\n",
    "    )\n",
    "      \n",
    "    assert abs(LPBSscore[0].item() - 1.0) < 1e-5\n",
    "    assert abs(LPBSscore[1].item() - (-3.0)) < 1e-5\n",
    "    assert abs(LPBSscore[2].item() - (-2.0)) < 1e-5\n",
    "\n",
    "def test_lpbs_less_target():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        LPBSscore = LPBS(\n",
    "            model = MODEL,\n",
    "            tokenizer = TOKENIZER,\n",
    "            sentences = SENTENCES[:1],\n",
    "            target_words = TARGET_WORDS_LPBS,\n",
    "            fill_words = FILL_WORDS,\n",
    "            mask_indices = MASK_INDICES\n",
    "        )\n",
    "    assert \"Different number of sentences\" in excinfo\n",
    "\n",
    "def test_lpbs_less_target():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        LPBSscore = LPBS(\n",
    "            model = MODEL,\n",
    "            tokenizer = TOKENIZER,\n",
    "            sentences = SENTENCES,\n",
    "            target_words = TARGET_WORDS_LPBS[:1],\n",
    "            fill_words = FILL_WORDS,\n",
    "            mask_indices = MASK_INDICES\n",
    "        )\n",
    "    assert \"Different number of sentences and target words\" in excinfo\n",
    "\n",
    "def test_lpbs_less_fill():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        LPBSscore = LPBS(\n",
    "            model = MODEL,\n",
    "            tokenizer = TOKENIZER,\n",
    "            sentences = SENTENCES,\n",
    "            target_words = TARGET_WORDS_LPBS,\n",
    "            fill_words = FILL_WORDS[:1],\n",
    "            mask_indices = MASK_INDICES\n",
    "        )\n",
    "    assert \"Different number of sentences and fill words\" in excinfo\n",
    "\n",
    "def test_lpbs_less_masks():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        LPBSscore = LPBS(\n",
    "            model = MODEL,\n",
    "            tokenizer = TOKENIZER,\n",
    "            sentences = SENTENCES,\n",
    "            target_words = TARGET_WORDS_LPBS,\n",
    "            fill_words = FILL_WORDS,\n",
    "            mask_indices = MASK_INDICES[:1]\n",
    "        )\n",
    "    assert \"Different number of sentences and mask indices\" in excinfo\n",
    "\n",
    "def test_lpbs_no_pairs():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        LPBSscore = LPBS(\n",
    "            model = MODEL,\n",
    "            tokenizer = TOKENIZER,\n",
    "            sentences = SENTENCES,\n",
    "            target_words = [('he', 'she', 'it')]*3,\n",
    "            fill_words = FILL_WORDS,\n",
    "            mask_indices = MASK_INDICES\n",
    "        )\n",
    "    assert \"Target words must consist of pairs of words\" in excinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c535245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cbs_type():\n",
    "    CBSscore = CBS(\n",
    "        model = MODEL,\n",
    "        tokenizer = TOKENIZER,\n",
    "        sentences = SENTENCES,\n",
    "        target_words = TARGET_WORDS_CBS,\n",
    "        fill_words = FILL_WORDS,\n",
    "        mask_indices = MASK_INDICES\n",
    "    )\n",
    "    assert isinstance(CBSscore, torch.Size)\n",
    "    assert CBSscore.shape == torch.Size([3])\n",
    "\n",
    "def test_cbs_value():\n",
    "    CBSscore = CBS(\n",
    "        model = MODEL,\n",
    "        tokenizer = TOKENIZER,\n",
    "        sentences = SENTENCES,\n",
    "        target_words = TARGET_WORDS_CBS,\n",
    "        fill_words = FILL_WORDS,\n",
    "        mask_indices = MASK_INDICES\n",
    "    )\n",
    "      \n",
    "    assert abs(CBSscore[0].item() - 1/3) < 1e-5\n",
    "    assert abs(CBSscore[1].item() - 13/3) < 1e-5\n",
    "    assert abs(CBSscore[2].item() - 4.0) < 1e-5\n",
    "\n",
    "def test_cbs_less_target():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        CBSscore = CBS(\n",
    "            model = MODEL,\n",
    "            tokenizer = TOKENIZER,\n",
    "            sentences = SENTENCES[:1],\n",
    "            target_words = TARGET_WORDS_CBS,\n",
    "            fill_words = FILL_WORDS,\n",
    "            mask_indices = MASK_INDICES\n",
    "        )\n",
    "    assert \"Different number of sentences\" in excinfo\n",
    "\n",
    "def test_cbs_less_target():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        CBSscore = CBS(\n",
    "            model = MODEL,\n",
    "            tokenizer = TOKENIZER,\n",
    "            sentences = SENTENCES,\n",
    "            target_words = TARGET_WORDS_CBS[:1],\n",
    "            fill_words = FILL_WORDS,\n",
    "            mask_indices = MASK_INDICES\n",
    "        )\n",
    "    assert \"Different number of sentences and target words\" in excinfo\n",
    "\n",
    "def test_cbs_less_fill():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        CBSscore = CBS(\n",
    "            model = MODEL,\n",
    "            tokenizer = TOKENIZER,\n",
    "            sentences = SENTENCES,\n",
    "            target_words = TARGET_WORDS_CBS,\n",
    "            fill_words = FILL_WORDS[:1],\n",
    "            mask_indices = MASK_INDICES\n",
    "        )\n",
    "    assert \"Different number of sentences and fill words\" in excinfo\n",
    "\n",
    "def test_cbs_less_masks():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        CBSscore = CBS(\n",
    "            model = MODEL,\n",
    "            tokenizer = TOKENIZER,\n",
    "            sentences = SENTENCES,\n",
    "            target_words = TARGET_WORDS_CBS,\n",
    "            fill_words = FILL_WORDS,\n",
    "            mask_indices = MASK_INDICES[:1]\n",
    "        )\n",
    "    assert \"Different number of sentences and mask indices\" in excinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a704ca6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DummyModel.__call__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      1\u001b[39m PLL_SENTENCES = [\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhe is an exemplary doctor\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mshe is an exemplary doctor\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhe is a lovely nurse\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mshe is a lovely nurse\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m ]\n\u001b[32m      8\u001b[39m TARGET_WORDS_CPS = [\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhe\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mshe\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhe\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mshe\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     13\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m CPSscore = \u001b[43mCPS\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOKENIZER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPLL_SENTENCES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_words\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mTARGET_WORDS_CPS\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/FairLangProc/FairLangProc/metrics/probability.py:463\u001b[39m, in \u001b[36mCPS\u001b[39m\u001b[34m(model, tokenizer, sentences, target_words)\u001b[39m\n\u001b[32m    460\u001b[39m     target_id = target_ids[sentence]\n\u001b[32m    461\u001b[39m     score = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     score = \u001b[43mMaskedPseudoLogLikelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcls_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_id\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m     \n\u001b[32m    471\u001b[39m     scores.append(score)\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/FairLangProc/FairLangProc/metrics/probability.py:374\u001b[39m, in \u001b[36mMaskedPseudoLogLikelihood\u001b[39m\u001b[34m(model, input_ids, target_id, mask_id, cls_id, pad_id)\u001b[39m\n\u001b[32m    371\u001b[39m masked_words = torch.tensor(masked_words)\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_sentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m     logits = outputs.logits\n\u001b[32m    376\u001b[39m     logProb = torch.log(F.softmax(logits, dim = \u001b[32m1\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: DummyModel.__call__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "PLL_SENTENCES = [\n",
    "    'he is an exemplary doctor',\n",
    "    'she is an exemplary doctor',\n",
    "    'he is a lovely nurse',\n",
    "    'she is a lovely nurse'\n",
    "]\n",
    "\n",
    "TARGET_WORDS_CPS = [\n",
    "    'he',\n",
    "    'she',\n",
    "    'he',\n",
    "    'she'\n",
    "]\n",
    "\n",
    "CPSscore = CPS(\n",
    "    model = MODEL,\n",
    "    tokenizer = TOKENIZER,\n",
    "    sentences = PLL_SENTENCES,\n",
    "    target_words = TARGET_WORDS_CPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebfa99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENIZER.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb033a",
   "metadata": {},
   "source": [
    "## Test embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from math import abs\n",
    "\n",
    "import torch\n",
    "import pytest\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")) if \"__file__\" in globals() else os.path.abspath(\"..\")\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "\n",
    "from FairLangProc.metrics import WEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9aacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyWEAT(WEAT):\n",
    "    def _get_embedding(self, outputs):\n",
    "        return outputs\n",
    "\n",
    "def test_cosine_similarity():\n",
    "    tokenizer = DummyTokenizer()\n",
    "    model = DummyModel()\n",
    "    pass\n",
    "\n",
    "def test_effect_size():\n",
    "    pass\n",
    "\n",
    "def test_metric():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d6ce6",
   "metadata": {},
   "source": [
    "## Test generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bab6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pytest\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")) if \"__file__\" in globals() else os.path.abspath(\"..\")\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "\n",
    "from FairLangProc.metrics import DemRep, StereoAsoc, HONEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008f7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDERED_WORDS = {\n",
    "    'male': ['he', 'him', 'his'],\n",
    "    'female': ['she', 'her', 'actress', 'hers']\n",
    "    }\n",
    "\n",
    "ATTRIBUTES = GENDERED_WORDS.keys()\n",
    "\n",
    "SENTENCES = [\n",
    "    'She is such a good match to him.',\n",
    "    'He is trying way too hard to be an actor.',\n",
    "    'Her mother is trying to make ends meet.'\n",
    "    'My aunt is baking, do you want to try?'\n",
    "]\n",
    "\n",
    "def test_demographic_representation_type():\n",
    "    DR = DemRep(sentences = SENTENCES, demWords = GENDERED_WORDS)\n",
    "    assert isinstance(DR, dict)\n",
    "\n",
    "def test_demographic_representation_keys():\n",
    "    DR = DemRep(sentences = SENTENCES, demWords = GENDERED_WORDS)\n",
    "    assert len(DR.keys()) == 2\n",
    "\n",
    "def test_demographic_representation_values():\n",
    "    DR = DemRep(sentences = SENTENCES, demWords = GENDERED_WORDS)\n",
    "    assert DR['male'] == 1\n",
    "    assert DR['female'] == 2\n",
    "\n",
    "def test_demographic_representation_empty_demwords():\n",
    "    DR = DemRep(sentences = SENTENCES, demWords = {})\n",
    "    assert DR == {}\n",
    "\n",
    "def test_demographic_representation_empty_sentences():\n",
    "    DR = DemRep(sentences = [], demWords = GENDERED_WORDS)\n",
    "    assert len(DR.keys()) == 2\n",
    "    assert DR['male'] == 0\n",
    "    assert DR['female'] == 0\n",
    "\n",
    "def test_demographic_representation_empty_demwords_sentences():\n",
    "    DR = DemRep(sentences = [], demWords = {})\n",
    "    assert DR == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb23db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_WORDS = ['mother', 'baking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf23fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stereorep_type():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = GENDERED_WORDS, targetWords = TARGET_WORDS)\n",
    "    assert isinstance(ST, dict)\n",
    "    for key in ST.keys():\n",
    "        assert isinstance(ST[key], dict)\n",
    "\n",
    "def test_stereorep_keys():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = GENDERED_WORDS, targetWords = TARGET_WORDS)\n",
    "    assert len(ST.keys()) == 2\n",
    "    for key in ST.keys():\n",
    "        assert len(ST[key].keys()) == 2\n",
    "\n",
    "def test_stereorep_values():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = GENDERED_WORDS, targetWords = TARGET_WORDS)\n",
    "    assert ST['mother']['male'] == 0\n",
    "    assert ST['mother']['female'] == 1\n",
    "    assert ST['baking']['male'] == 0\n",
    "    assert ST['baking']['female'] == 0\n",
    "\n",
    "def test_stereorep_empty_target():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = GENDERED_WORDS, targetWords = [])\n",
    "    assert ST == {}\n",
    "\n",
    "def test_stereorep_empty_dem():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = {}, targetWords = TARGET_WORDS)\n",
    "    assert ST['mother'] == {}\n",
    "    assert ST['baking'] == {}\n",
    "\n",
    "def test_stereorep_empty_sentences():\n",
    "    ST = StereoAsoc(sentences = [], demWords = GENDERED_WORDS, targetWords = TARGET_WORDS)\n",
    "    assert ST['mother']['male'] == 0\n",
    "    assert ST['mother']['female'] == 0\n",
    "    assert ST['baking']['male'] == 0\n",
    "    assert ST['baking']['female'] == 0\n",
    "\n",
    "def test_stereorep_empty_dem_sentences():\n",
    "    ST = StereoAsoc(sentences = [], demWords = {}, targetWords = TARGET_WORDS)\n",
    "    assert ST['mother'] == {}\n",
    "    assert ST['baking'] == {}\n",
    "\n",
    "def test_stereorep_empty_dem_target():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = {}, targetWords = [])\n",
    "    assert ST == {}\n",
    "\n",
    "def test_stereorep_empty_sentences_target():\n",
    "    ST = StereoAsoc(sentences = [], demWords = GENDERED_WORDS, targetWords = [])\n",
    "    assert ST == {}\n",
    "\n",
    "def test_stereorep_empty_dem_sentences_target():\n",
    "    ST = StereoAsoc(sentences = [], demWords = {}, targetWords = [])\n",
    "    assert ST == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0596a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS = [\n",
    "    ['he is so stupid', 'he is such a fool', 'he is so misunderstood'],\n",
    "    ['she is so bossy', 'she is an incompetent manager', 'she does what is necessary'],\n",
    "    ['they were so agreeable', 'they were so nice to us', 'they showed hospitality']\n",
    "]\n",
    "\n",
    "COMPLETIONS_DIFFERENT_LENGTH = [\n",
    "    ['he is so stupid', 'he is such a fool', 'he is so misunderstood'],\n",
    "    ['she is so bossy', 'she is an incompetent manager'],\n",
    "    ['they were so agreeable', 'they were so nice to us', 'they showed hospitality']\n",
    "]\n",
    "\n",
    "COMPLETIONS_WITHOUT_LIST = [\n",
    "    ['he is so stupid', 'he is such a fool', 'he is so misunderstood'],\n",
    "    ('she is so bossy', 'she is an incompetent manager', 'she does what is necessary'),\n",
    "    ['they were so agreeable', 'they were so nice to us', 'they showed hospitality']\n",
    "]\n",
    "\n",
    "HURTLEX = ['fool', 'stupid', 'incompetent']\n",
    "\n",
    "def test_honest_type():\n",
    "    honest = HONEST(completions = COMPLETIONS, hurtLex = HURTLEX)\n",
    "    assert isinstance(honest, float)\n",
    "\n",
    "def test_honest_value():\n",
    "    honest = HONEST(completions = COMPLETIONS, hurtLex = HURTLEX)\n",
    "    assert abs(honest - 1/3) < 1e-15\n",
    "\n",
    "def test_honest_empty_hurt():\n",
    "    honest = HONEST(completions = COMPLETIONS, hurtLex = [])\n",
    "    assert abs(honest - 0.0) < 1e-15\n",
    "\n",
    "def test_honest_empty_completions():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        honest = HONEST(completions = [], hurtLex = HURTLEX)\n",
    "    assert \"completions is empty\" in excinfo\n",
    "\n",
    "def test_honest_not_list():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        honest = HONEST(completions = {}, hurtLex = HURTLEX)\n",
    "    assert \"completions is not a list\" in excinfo\n",
    "\n",
    "def test_element_not_list():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        honest = HONEST(completions = COMPLETIONS_WITHOUT_LIST, hurtLex = HURTLEX)\n",
    "    assert \"completions is not a list of lists\" in excinfo\n",
    "\n",
    "def test_honest_different_length():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        honest = HONEST(completions = COMPLETIONS_DIFFERENT_LENGTH, hurtLex = HURTLEX)\n",
    "    assert \"Number of completions is not uniform\" in excinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80077b7e",
   "metadata": {},
   "source": [
    "# Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c52f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FairLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
