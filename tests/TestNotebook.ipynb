{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f077304",
   "metadata": {},
   "source": [
    "# Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36538d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pytest\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset as PtDataset\n",
    "from datasets import Dataset as HfDataset\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")) if \"__file__\" in globals() else os.path.abspath(\"..\")\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "\n",
    "from FairLangProc.datasets.fairness_datasets import BiasDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fda3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPLEMENTED = [\n",
    "    \"BBQ\",\n",
    "    \"BEC-Pro\",\n",
    "    \"BOLD\",\n",
    "    \"BUG\",\n",
    "    \"CrowS-Pairs\",\n",
    "    \"GAP\",\n",
    "    \"StereoSet\",\n",
    "    \"UnQover\",\n",
    "    \"WinoBias+\",\n",
    "    \"WinoBias\",\n",
    "    \"Winogender\"\n",
    "]\n",
    "\n",
    "DATASETS = [\n",
    "    \"BBQ\",\n",
    "    \"BEC-Pro\",\n",
    "    \"BOLD\",\n",
    "    \"BUG\",\n",
    "    \"Bias-NLI\",\n",
    "    \"CrowS-Pairs\",\n",
    "    \"GAP\",\n",
    "    \"Grep-BiasIR\",\n",
    "    \"HONEST\",\n",
    "    \"HolisticBias\",\n",
    "    \"PANDA\",\n",
    "    \"RedditBias\",\n",
    "    \"StereoSet\",\n",
    "    \"TrustGPT\",\n",
    "    \"UnQover\",\n",
    "    \"WinoBias\",\n",
    "    \"WinoBias+\",\n",
    "    \"WinoQueer\",\n",
    "    \"Winogender\",\n",
    "]\n",
    "\n",
    "REMAINING = [dataset for dataset in DATASETS if dataset not in IMPLEMENTED]\n",
    "\n",
    "CONFIGURATIONS = {\n",
    "    \"BBQ\": [\"Age\", \"Disability_Status\", \"Gender_identity\", \"Nationality\", \"Physical_appearance\", \"Race_ethnicity\", \"Race_x_gender\", \"Race_x_SES\", \"Religion\", \"SES\", \"Sexual_orientation\", \"all\"],\n",
    "    \"BEC-Pro\": [\"english\", \"german\", \"all\"],\n",
    "    \"BOLD\": [\"prompts\", \"wikipedia\", \"all\"],\n",
    "    \"BUG\": [\"balanced\", \"full\", \"gold\", \"all\"],\n",
    "    \"Bias-NLI\": [\"process\", \"load\", \"all\"],\n",
    "    \"CrowS-Pairs\": [\"\"],\n",
    "    \"GAP\": [\"\"],\n",
    "    \"Grep-BiasIR\": [\"queries\", \"documents\", \"relevance\", \"all\"],\n",
    "    \"HolisticBias\": [\"noun_phrases\", \"sentences\", \"all\"],\n",
    "    \"PANDA\": [\"train\", \"test\", \"dev\", \"all\"],\n",
    "    \"RedditBias\": [\"posts\", \"comments\", \"annotations\", \"all\"],\n",
    "    \"StereoSet\": [\"word\", \"sentence\", \"all\"],\n",
    "    \"TrustGPT\": [\"process\", \"load\", \"all\", \"benchmarks\"],\n",
    "    \"UnQover\": [\"questions\", \"answers\", \"annotations\"],\n",
    "    \"WinoBias\": [\"pairs\", \"WinoBias\"],\n",
    "    \"WinoBias+\": [\"\"],\n",
    "    \"WinoQueer\": [\"sentences\", \"templates\", \"annotations\", \"all\"],\n",
    "    \"Winogender\": [\"\"],\n",
    "}\n",
    "\n",
    "FORMATS = [\"hf\", \"pt\", \"raw\"]\n",
    "\n",
    "CLASS_DICT = {\n",
    "    \"hf\": HfDataset,\n",
    "    \"pt\": PtDataset,\n",
    "    \"raw\": pd.DataFrame\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb867e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CASES_FORMAT = [\n",
    "    (dataset, config, format)\n",
    "    for dataset in CONFIGURATIONS.keys()\n",
    "    for config in CONFIGURATIONS[dataset] \n",
    "    for format in FORMATS if dataset in IMPLEMENTED\n",
    "]\n",
    "\n",
    "@pytest.mark.parametrize(\"dataset, config, format\", TEST_CASES_FORMAT)\n",
    "def test_format(dataset, config, format):\n",
    "    result = BiasDataLoader(dataset = dataset, config = config, format = format)\n",
    "    assert isinstance(result, dict)\n",
    "    for key in result:\n",
    "        assert isinstance(result[key], CLASS_DICT[format])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37c645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_columns():\n",
    "    for dataset in CONFIGURATIONS.keys():\n",
    "        if dataset in IMPLEMENTED:\n",
    "            result = BiasDataLoader(dataset = dataset, config = 'all', format = 'raw')\n",
    "            if result is None:\n",
    "                result = BiasDataLoader(dataset = dataset, config = '', format = 'raw')\n",
    "            try:\n",
    "                print(dataset)\n",
    "                print(list(result[list(result.keys())[0]].keys()))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def _get_rows():\n",
    "    for dataset in CONFIGURATIONS.keys():\n",
    "        if dataset in IMPLEMENTED:\n",
    "            result = BiasDataLoader(dataset = dataset, config = 'all', format = 'raw')\n",
    "            if result is None:\n",
    "                result = BiasDataLoader(dataset = dataset, config = '', format = 'raw')\n",
    "            try:\n",
    "                string = f\"\\\"{dataset}\\\": {{\"\n",
    "                for data in result.keys():\n",
    "                    if data == 'templates' and dataset == 'BBQ':\n",
    "                        continue\n",
    "                    string += f\"\\\"{data}\\\": {len(result[data].index)}, \"\n",
    "                string += \"}, \"\n",
    "                print(string)\n",
    "            except:\n",
    "                print(dataset + \": nothing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a467f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = {\n",
    "    \"BBQ\": ['example_id', 'question_index', 'question_polarity', 'context_condition', 'category', 'answer_info', 'additional_metadata', 'context', 'question', 'ans0', 'ans1', 'ans2', 'label'],\n",
    "    \"BEC-Pro\": ['Unnamed: 0', 'Sentence', 'Sent_TM', 'Sent_AM', 'Sent_TAM', 'Template', 'Person', 'Gender', 'Profession', 'Prof_Gender'],\n",
    "    \"BOLD\": ['gender_prompt.json', 'political_ideology_prompt.json', 'profession_prompt.json', 'race_prompt.json', 'religious_ideology_prompt.json'],\n",
    "    \"BUG\": ['Unnamed: 0', 'sentence_text', 'tokens', 'profession', 'g', 'profession_first_index', 'g_first_index', 'predicted gender', 'stereotype', 'distance', 'num_of_pronouns', 'corpus', 'data_index'],\n",
    "    \"CrowS-Pairs\": ['Unnamed: 0', 'sent_more', 'sent_less', 'stereo_antistereo', 'bias_type', 'annotations', 'anon_writer', 'anon_annotators'],\n",
    "    \"GAP\": ['ID', 'Text', 'Pronoun', 'Pronoun-offset', 'A', 'A-offset', 'A-coref', 'B', 'B-offset', 'B-coref', 'URL'],\n",
    "    \"HolisticBias\": None,\n",
    "    \"StereoSet\": ['options', 'context', 'target', 'bias_type', 'labels'],\n",
    "    \"WinoBias+\": ['gendered', 'neutral'],\n",
    "    \"WinoBias\": ['sentence', 'entity', 'pronoun'],\n",
    "    \"Winogender\": ['sentid', 'sentence']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59239f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = {\n",
    "    \"BBQ\": {\"Age.jsonl\": 3680, \"Disability_status.jsonl\": 1556, \"Gender_identity.jsonl\": 5672, \"Nationality.jsonl\": 3080, \"Physical_appearance.jsonl\": 1576, \"Race_ethnicity.jsonl\": 6880, \"Race_x_SES.jsonl\": 11160, \"Race_x_gender.jsonl\": 15960, \"Religion.jsonl\": 1200, \"SES.jsonl\": 6864, \"Sexual_orientation.jsonl\": 864, \"additional_metadata.csv\": 58556, },\n",
    "    \"BEC-Pro\": {\"english\": 5400, \"german\": 5400, }, \n",
    "    \"BUG\": {\"balanced_BUG.csv\": 25504, \"full_BUG.csv\": 105687, \"gold_BUG.csv\": 1717, }, \n",
    "    \"CrowS-Pairs\": {\"data\": 1508, }, \n",
    "    \"GAP\": {\"gap-development.tsv\": 2000, \"gap-test.tsv\": 2000, \"gap-validation.tsv\": 454, }, \n",
    "    \"StereoSet\": {\"test_sentence\": 6374, \"test_word\": 6392, \"dev_sentence\": 2123, \"dev_word\": 2106, }, \n",
    "    \"WinoBias\": {\"anti_stereotyped_type1.txt.dev\": 396, \"anti_stereotyped_type1.txt.test\": 396, \"anti_stereotyped_type2.txt.dev\": 396, \"anti_stereotyped_type2.txt.test\": 396, \"pro_stereotyped_type1.txt.dev\": 396, \"pro_stereotyped_type1.txt.test\": 396, \"pro_stereotyped_type2.txt.dev\": 396, \"pro_stereotyped_type2.txt.test\": 396, }, \n",
    "    \"WinoBias+\": {\"data\": 3167, }, \n",
    "    \"Winogender\": {\"data\": 720, }, \n",
    "}\n",
    "\n",
    "TEST_CASES_COLUMN_TYPES = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc3b414",
   "metadata": {},
   "source": [
    "# Test metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8a112",
   "metadata": {},
   "source": [
    "## Test probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f0bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01eb033a",
   "metadata": {},
   "source": [
    "## Test embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1539d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce1d6ce6",
   "metadata": {},
   "source": [
    "## Test generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bab6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pytest\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")) if \"__file__\" in globals() else os.path.abspath(\"..\")\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "\n",
    "from FairLangProc.metrics import DemRep, StereoAsoc, HONEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008f7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDERED_WORDS = {\n",
    "    'male': ['he', 'him', 'his'],\n",
    "    'female': ['she', 'her', 'actress', 'hers']\n",
    "    }\n",
    "\n",
    "ATTRIBUTES = GENDERED_WORDS.keys()\n",
    "\n",
    "SENTENCES = [\n",
    "    'She is such a good match to him.',\n",
    "    'He is trying way too hard to be an actor.',\n",
    "    'Her mother is trying to make ends meet.'\n",
    "    'My aunt is baking, do you want to try?'\n",
    "]\n",
    "\n",
    "def test_demographic_representation_type():\n",
    "    DR = DemRep(sentences = SENTENCES, demWords = GENDERED_WORDS)\n",
    "    assert isinstance(DR, dict)\n",
    "\n",
    "def test_demographic_representation_keys():\n",
    "    DR = DemRep(sentences = SENTENCES, demWords = GENDERED_WORDS)\n",
    "    assert len(DR.keys()) == 2\n",
    "\n",
    "def test_demographic_representation_values():\n",
    "    DR = DemRep(sentences = SENTENCES, demWords = GENDERED_WORDS)\n",
    "    assert DR['male'] == 1\n",
    "    assert DR['female'] == 2\n",
    "\n",
    "def test_demographic_representation_empty_demwords():\n",
    "    DR = DemRep(sentences = SENTENCES, demWords = {})\n",
    "    assert DR == {}\n",
    "\n",
    "def test_demographic_representation_empty_sentences():\n",
    "    DR = DemRep(sentences = [], demWords = GENDERED_WORDS)\n",
    "    assert len(DR.keys()) == 2\n",
    "    assert DR['male'] == 0\n",
    "    assert DR['female'] == 0\n",
    "\n",
    "def test_demographic_representation_empty_demwords_sentences():\n",
    "    DR = DemRep(sentences = [], demWords = {})\n",
    "    assert DR == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb23db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_WORDS = ['mother', 'baking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf23fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stereorep_type():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = GENDERED_WORDS, targetWords = TARGET_WORDS)\n",
    "    assert isinstance(ST, dict)\n",
    "    for key in ST.keys():\n",
    "        assert isinstance(ST[key], dict)\n",
    "\n",
    "def test_stereorep_keys():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = GENDERED_WORDS, targetWords = TARGET_WORDS)\n",
    "    assert len(ST.keys()) == 2\n",
    "    for key in ST.keys():\n",
    "        assert len(ST[key].keys()) == 2\n",
    "\n",
    "def test_stereorep_values():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = GENDERED_WORDS, targetWords = TARGET_WORDS)\n",
    "    assert ST['mother']['male'] == 0\n",
    "    assert ST['mother']['female'] == 1\n",
    "    assert ST['baking']['male'] == 0\n",
    "    assert ST['baking']['female'] == 0\n",
    "\n",
    "def test_stereorep_empty_target():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = GENDERED_WORDS, targetWords = [])\n",
    "    assert ST == {}\n",
    "\n",
    "def test_stereorep_empty_dem():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = {}, targetWords = TARGET_WORDS)\n",
    "    assert ST['mother'] == {}\n",
    "    assert ST['baking'] == {}\n",
    "\n",
    "def test_stereorep_empty_sentences():\n",
    "    ST = StereoAsoc(sentences = [], demWords = GENDERED_WORDS, targetWords = TARGET_WORDS)\n",
    "    assert ST['mother']['male'] == 0\n",
    "    assert ST['mother']['female'] == 0\n",
    "    assert ST['baking']['male'] == 0\n",
    "    assert ST['baking']['female'] == 0\n",
    "\n",
    "def test_stereorep_empty_dem_sentences():\n",
    "    ST = StereoAsoc(sentences = [], demWords = {}, targetWords = TARGET_WORDS)\n",
    "    assert ST['mother'] == {}\n",
    "    assert ST['baking'] == {}\n",
    "\n",
    "def test_stereorep_empty_dem_target():\n",
    "    ST = StereoAsoc(sentences = SENTENCES, demWords = {}, targetWords = [])\n",
    "    assert ST == {}\n",
    "\n",
    "def test_stereorep_empty_sentences_target():\n",
    "    ST = StereoAsoc(sentences = [], demWords = GENDERED_WORDS, targetWords = [])\n",
    "    assert ST == {}\n",
    "\n",
    "def test_stereorep_empty_dem_sentences_target():\n",
    "    ST = StereoAsoc(sentences = [], demWords = {}, targetWords = [])\n",
    "    assert ST == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0596a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS = [\n",
    "    ['he is so stupid', 'he is such a fool', 'he is so misunderstood'],\n",
    "    ['she is so bossy', 'she is an incompetent manager', 'she does what is necessary'],\n",
    "    ['they were so agreeable', 'they were so nice to us', 'they showed hospitality']\n",
    "]\n",
    "\n",
    "COMPLETIONS_DIFFERENT_LENGTH = [\n",
    "    ['he is so stupid', 'he is such a fool', 'he is so misunderstood'],\n",
    "    ['she is so bossy', 'she is an incompetent manager'],\n",
    "    ['they were so agreeable', 'they were so nice to us', 'they showed hospitality']\n",
    "]\n",
    "\n",
    "COMPLETIONS_WITHOUT_LIST = [\n",
    "    ['he is so stupid', 'he is such a fool', 'he is so misunderstood'],\n",
    "    ('she is so bossy', 'she is an incompetent manager', 'she does what is necessary'),\n",
    "    ['they were so agreeable', 'they were so nice to us', 'they showed hospitality']\n",
    "]\n",
    "\n",
    "HURTLEX = ['fool', 'stupid', 'incompetent']\n",
    "\n",
    "def test_honest_type():\n",
    "    honest = HONEST(completions = COMPLETIONS, hurtLex = HURTLEX)\n",
    "    assert isinstance(honest, float)\n",
    "\n",
    "def test_honest_value():\n",
    "    honest = HONEST(completions = COMPLETIONS, hurtLex = HURTLEX)\n",
    "    assert abs(honest - 1/3) < 1e-15\n",
    "\n",
    "def test_honest_empty_hurt():\n",
    "    honest = HONEST(completions = COMPLETIONS, hurtLex = [])\n",
    "    assert abs(honest - 0.0) < 1e-15\n",
    "\n",
    "def test_honest_empty_completions():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        honest = HONEST(completions = [], hurtLex = HURTLEX)\n",
    "    assert \"completions is empty\" in excinfo\n",
    "\n",
    "def test_honest_not_list():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        honest = HONEST(completions = {}, hurtLex = HURTLEX)\n",
    "    assert \"completions is not a list\" in excinfo\n",
    "\n",
    "def test_element_not_list():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        honest = HONEST(completions = COMPLETIONS_WITHOUT_LIST, hurtLex = HURTLEX)\n",
    "    assert \"completions is not a list of lists\" in excinfo\n",
    "\n",
    "def test_honest_different_length():\n",
    "    with pytest.raises(AssertionError) as excinfo:\n",
    "        honest = HONEST(completions = COMPLETIONS_DIFFERENT_LENGTH, hurtLex = HURTLEX)\n",
    "    assert \"Number of completions is not uniform\" in excinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80077b7e",
   "metadata": {},
   "source": [
    "# Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c52f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
